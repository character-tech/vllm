FROM us-central1-docker.pkg.dev/character-ai/vllm/vllm-forked:d0ab76f as builder
COPY . /mnt/vllm

# Install without build isolation to preserve existing binaries
RUN pip install --no-build-isolation --no-deps /mnt/vllm --force-reinstall

RUN rm -rf /mnt/vllm
RUN python3 -c "import vllm; print('Custom vLLM loaded successfully')"
RUN python3 -m pip install --no-cache-dir --upgrade \
      opentelemetry-api==1.26.0 \
      opentelemetry-sdk==1.26.0 \
      opentelemetry-exporter-gcp-trace==1.7.0 \
      opentelemetry-exporter-otlp==1.26.0 \
      opentelemetry-semantic-conventions-ai==0.4.1 \
      google-cloud-trace==1.7.1

ENV HF_HOME=/huggingface/cache
